## Redis如何删除过期Key

- 定期删除：redis默认是每隔 100ms 就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！
- 惰性删除：读取到数据时，发现数据已经过期，则删除这个Key。

**产生的问题** ：  
如果Key很多，定期删除没有来得及扫描到过期的Key，而这些数据又没有被读取，这样就不会被删除，在内存中形成的垃圾数据，这时候怎么办呢？就是下面的内存淘汰机制。

## 内存淘汰机制

- **volatile-lru** ：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
- **volatile-ttl** ：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
- **volatile-random** ：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
- **allkeys-lru** ：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）
- **allkeys-random** ：从数据集（server.db[i].dict）中任意选择数据淘汰
- **no-eviction** ：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！
4.0版本后增加以下两种：
- **volatile-lfu** ：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
- **allkeys-lfu** ：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key

更多：[Redis内存淘汰机制](Redis内存淘汰机制.md)

## 缓存雪崩

缓存同一时间失效导致去查询数据库。

**解决：**  
- Redis服务器正常，缓存同时过期：
	- 可以在过期时间上加上随机数，避免大面积失效。
	- 可以设置缓存永久不过期并采取适当的内存淘汰机制，如秒杀过后要删除无用的缓存。
	- 增加限流或降级策略，保证MySQL稳定。
- Redis服务器挂掉：
	- 增加服务器实例保证可用性。
	- 利用持久化恢复。

## 缓存穿透

虚假数据请求导致认为缓存不存在去查询数据库。

**解决：**  
- 将不存在的Key缓存为Null，下次就可以不走DB。（浪费内存，也并不能保证下次请求会来）
- 做一些风控安全限制。（同一时间IP、请求次数等限制）
- 使用布隆过滤器进行过滤。（推荐）将有缓存的数据都放到布隆过滤器中，请求来时Cache不存在，查询布隆过滤器就知道DB中是否存在。

## 缓存击穿

缓存的都不是非热点数据导致去查询数据库。

**解决：**  
优化热点数据的计算方式。淘汰缓存中的非热点数据。

## 如何解决 Redis 的并发竞争 Key 问题

所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！

**解决：**  
- 放到有序的消息队列中一次操作。
- 使用分布式锁对Key进行顺序操作。

## Redis为何这么快

- 完全基于内存操作
- IO多路复用
- 单线程模型
- 高效的数据结构
- 合理的数据编码

## 什么是RDB

redis内存快照，通过save或者bgsave，把某一时刻数据持久化到磁盘上生成快照。

优：
- 二进制压缩处理，恢复速度比较快。
- 适合容灾备份处理。

缺：
- rdb生成时磁盘开销比较大，所以耗时，可能导致上次还没持久化完成，下一次已经持久化动作已经开始了。
- save处理会阻塞主线程，bgsave处理fork子进程时候会阻塞主线程。
- 如果间隔时间过大，数据丢失很多。

## 生成RDB快照时候主线程还能处理请求吗

bgsave命令通过fork一个子进程完成快照的生成，不影响主线程处理请求。通过Copy On Write完成数据的一致性，主线程处理写请求时还会将数据写入缓冲区，子进程读取缓冲区保证数据的一致性。

## 什么是AOF

将redis的写请求顺序的写入文件中记录下来，采用写后日志形式，先将操作写入缓冲区，然后在同步到磁盘中。所以提供了3中配置策略，`always`，`everysec`，`no`。

优：
- 数据尽可能的不会丢失，`always` 策略完全不会丢失数据。
- 备份性能相对于rdb高。

缺： 
- 文件过大（有重写机制可以优化）
- 恢复不过rdb快。

## 如何实现数据尽可能少丢失又能兼顾性能呢

可以采用混合模式，通过rdb存储数据快照，每次快照之间的写操作通过aof来记录，这样先恢复rdb中的数据，在执行aof中数据即可。恢复比纯aof快，还可以使得aof文件不至于过大。

## 主从之间数据如何保证一致性

采用读写分离的模式。只有主库才能写数据，同步给从库，这样保证了数据的一致性。

## 主从复制优点

- 负载均衡：主库写操作，从库读操作，减轻压力。
- 容灾恢复：当出库挂了，可以将从库变成主库继续提供服务，从库挂了多个从库的话不影响提供服务。
- 高可用基础：是哨兵和集群模式的基础。

## 主从复制如何同步数据

- 第一次全量同步：
	- 从库向主库发送`psync`命令，主库收到后回复runId和offset。如果offset为-1则开始全量同步。
	- 主库执行`bgsave`命令生成rdb快照，同时主库为每一个 slave 开辟一块 `replication buffer` 缓冲区记录从生成 RDB 文件开始收到的所有写命令。
	- 从库收到rdb快照清掉自身内存并将rdb文件加载到内存，并通过replication buffer同步生成快照时候的数据。
- 断线重连增量同步： 主库写命令都会写入repl_backlog_buffer，repl_backlog_buffer 是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容。主库发送`psync`命令的时候会带上自己的runId和offset，主库根据从库的offset发送后的命令。
- 正常运行时同步：主库与从库建立长连接，主库执行的命令直接同步给从库。

## 哨兵之间是如何知道彼此的？

基于redis的订阅发布机制，内部通过(__sentinel__:hello)通道交换彼此的信息。哨兵与master建立连接，利用master的订阅发布机制发布自己的信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口，从而相互发现建立连接。

## 哨兵如何监控slave

哨兵会向master发送`info replication`命令，由master返回slave信息。哨兵根据返回的信息与slave建立连接

## 哨兵如何完成故障转移

当一个哨兵与redis连接断开时候，便是主观下线，他会向其他哨兵询问这个redis是否还存活，如果超过设置的quorum数量，那么就认为他客观下线，移除他。

要完成故障转移，要先进行leader选举，由一个哨兵进行操作。当redis客观下线时，由主观下线的哨兵发起leader竞选，其他哨兵对其投票，当超过quorum票数时成为leader。

leader哨兵选出一个合适（slave-priority高的、同步offset最多的、runId最小的）的slave为master，并告诉其他的slave新的节点信息。当master重新上线后，将其变为slave，并告诉其新的master信息。

## 什么是集群模式

主从和哨兵只能完成数据的读写分离，并不能分担主库的写压力，所以集群相当于主从和哨兵的合成版本。多个主库通过crc16算法对数据进行分片在16384个slot槽下共同存储写数据，每个主库通过主从复制同步备份主库的数据。当主库挂了的时候通过哨兵机制对主库进行替换。

## 数据如何存储在redis实例上

通过key值计算出 crc16(key) % 16384 计算出 slot的值，通过slot的值找到对应的实例上。如果是连接的实例，那么就写数据，如果不是，那么就重定向到对应的实例上。

## cluster如何故障转移

各个节点故障转移与哨兵通讯基本一致，但是节点之间是通过Gossip协议通讯的。当slave发现master下线之后，向其他节点发送消息，其他节点也认为其下线时候，就会触发选主机制。

## 什么是 Redis 重定向机制

通过`moved`和 `ask` 机制。

- moved ：如果查询的key不在连接的机器，那么就通过moved重定向到对应的机器上。更新本地缓存。
- ask ：如果某个 slot 的数据比较多，部分迁移到新实例，还有一部分没有迁移。那么通过ask让其先到之前的机器上查询。不更新本地缓存。

